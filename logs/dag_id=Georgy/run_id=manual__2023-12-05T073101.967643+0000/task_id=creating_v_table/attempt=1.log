[2023-12-05T07:31:04.068+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: Georgy.creating_v_table manual__2023-12-05T07:31:01.967643+00:00 [queued]>
[2023-12-05T07:31:04.074+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: Georgy.creating_v_table manual__2023-12-05T07:31:01.967643+00:00 [queued]>
[2023-12-05T07:31:04.074+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 1
[2023-12-05T07:31:04.084+0000] {taskinstance.py:1380} INFO - Executing <Task(SnowflakeOperator): creating_v_table> on 2023-12-05 07:31:01.967643+00:00
[2023-12-05T07:31:04.088+0000] {standard_task_runner.py:57} INFO - Started process 363 to run task
[2023-12-05T07:31:04.090+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'Georgy', 'creating_v_table', 'manual__2023-12-05T07:31:01.967643+00:00', '--job-id', '171', '--raw', '--subdir', 'DAGS_FOLDER/test.py', '--cfg-path', '/tmp/tmpl0tis_lc']
[2023-12-05T07:31:04.091+0000] {standard_task_runner.py:85} INFO - Job 171: Subtask creating_v_table
[2023-12-05T07:31:04.124+0000] {task_command.py:415} INFO - Running <TaskInstance: Georgy.creating_v_table manual__2023-12-05T07:31:01.967643+00:00 [running]> on host 435c91f40721
[2023-12-05T07:31:04.182+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Gio' AIRFLOW_CTX_DAG_ID='Georgy' AIRFLOW_CTX_TASK_ID='creating_v_table' AIRFLOW_CTX_EXECUTION_DATE='2023-12-05T07:31:01.967643+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-12-05T07:31:01.967643+00:00'
[2023-12-05T07:31:04.183+0000] {sql.py:274} INFO - Executing: 
            CREATE OR REPLACE TABLE task1_v_table AS SELECT 
              CSV_PARSER.V
            -- Query the stage for one file or use a pattern for multiple
            FROM @MY_STAGE (FILE_FORMAT => TEXT_FORMAT, PATTERN=>'.*.csv.gz') STG
            -- Lateral join to call our UDTF
            JOIN LATERAL PARSE_CSV(STG.$1, ',', '"') 
              -- Partition by file to support multiple files at once
            OVER (PARTITION BY METADATA$FILENAME 
              -- Order by row number to ensure headers are first in each window
            ORDER BY METADATA$FILE_ROW_NUMBER) AS CSV_PARSER;
[2023-12-05T07:31:04.192+0000] {base.py:73} INFO - Using connection ID 'snowflake' for task execution.
[2023-12-05T07:31:04.199+0000] {base.py:73} INFO - Using connection ID 'snowflake' for task execution.
[2023-12-05T07:31:04.200+0000] {connection.py:314} INFO - Snowflake Connector for Python Version: 3.1.1, Python Version: 3.8.18, Platform: Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.2.5
[2023-12-05T07:31:04.200+0000] {connection.py:1050} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-12-05T07:31:04.201+0000] {connection.py:1060} INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.
[2023-12-05T07:31:04.201+0000] {connection.py:1068} INFO - Setting use_openssl_only mode to False
[2023-12-05T07:31:04.485+0000] {ssl_wrap_socket.py:100} INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.
[2023-12-05T07:31:04.761+0000] {cursor.py:804} INFO - query: [ALTER SESSION SET autocommit=False]
[2023-12-05T07:31:04.876+0000] {cursor.py:817} INFO - query execution done
[2023-12-05T07:31:04.876+0000] {cursor.py:959} INFO - Number of results in first chunk: 1
[2023-12-05T07:31:04.877+0000] {sql.py:418} INFO - Running statement: CREATE OR REPLACE TABLE task1_v_table AS SELECT 
              CSV_PARSER.V
            -- Query the stage for one file or use a pattern for multiple
            FROM @MY_STAGE (FILE_FORMAT => TEXT_FORMAT, PATTERN=>'.*.csv.gz') STG
            -- Lateral join to call our UDTF
            JOIN LATERAL PARSE_CSV(STG.$1, ',', '"') 
              -- Partition by file to support multiple files at once
            OVER (PARTITION BY METADATA$FILENAME 
              -- Order by row number to ensure headers are first in each window
            ORDER BY METADATA$FILE_ROW_NUMBER) AS CSV_PARSER;, parameters: None
[2023-12-05T07:31:04.877+0000] {cursor.py:804} INFO - query: [CREATE OR REPLACE TABLE task1_v_table AS SELECT CSV_PARSER.V -- Query the stage ...]
[2023-12-05T07:31:10.832+0000] {cursor.py:817} INFO - query execution done
[2023-12-05T07:31:10.833+0000] {cursor.py:959} INFO - Number of results in first chunk: 1
[2023-12-05T07:31:10.833+0000] {sql.py:427} INFO - Rows affected: 1
[2023-12-05T07:31:10.834+0000] {snowflake.py:427} INFO - Rows affected: 1
[2023-12-05T07:31:10.834+0000] {snowflake.py:428} INFO - Snowflake query id: 01b0c7c3-0000-c393-0001-691a00014b72
[2023-12-05T07:31:10.834+0000] {cursor.py:804} INFO - query: [COMMIT]
[2023-12-05T07:31:10.938+0000] {cursor.py:817} INFO - query execution done
[2023-12-05T07:31:10.938+0000] {cursor.py:959} INFO - Number of results in first chunk: 1
[2023-12-05T07:31:10.938+0000] {connection.py:640} INFO - closed
[2023-12-05T07:31:11.022+0000] {connection.py:646} INFO - No async queries seem to be running, deleting session
[2023-12-05T07:31:11.127+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=Georgy, task_id=creating_v_table, execution_date=20231205T073101, start_date=20231205T073104, end_date=20231205T073111
[2023-12-05T07:31:11.154+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2023-12-05T07:31:11.167+0000] {taskinstance.py:2776} INFO - 1 downstream tasks scheduled from follow-on schedule check
